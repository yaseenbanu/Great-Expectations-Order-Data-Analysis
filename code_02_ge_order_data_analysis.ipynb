{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+----------+------------+------------+\n",
      "|order_id|customer_id|order_date|order_amount|order_status|\n",
      "+--------+-----------+----------+------------+------------+\n",
      "|       1|         23|2024-04-05|      426.48|     pending|\n",
      "|       2|        316|2024-05-08|      483.77|     pending|\n",
      "|       3|        721|2023-12-14|      291.96|     pending|\n",
      "|       4|        481|2024-01-21|       53.94|   cancelled|\n",
      "|       5|        847|2024-05-15|      472.08|   cancelled|\n",
      "+--------+-----------+----------+------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType, DateType\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"LargeDatasetWithNoneExample\").getOrCreate()\n",
    "\n",
    "# Define schema\n",
    "schema = StructType([\n",
    "    StructField(\"order_id\", IntegerType(), True),\n",
    "    StructField(\"customer_id\", IntegerType(), True),\n",
    "    StructField(\"order_date\", DateType(), True),\n",
    "    StructField(\"order_amount\", DoubleType(), True),\n",
    "    StructField(\"order_status\", StringType(), True)\n",
    "])\n",
    "\n",
    "df = spark.read.format('csv').load(r\"data/orders.csv/\",schema = schema,header=True)\n",
    "\n",
    "df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You appear to be using a legacy capability with the latest config version (3.0).\n",
      "    Your data context with this configuration version uses validation_operators, which are being deprecated.  Please consult the V3 API migration guide https://docs.greatexpectations.io/docs/guides/miscellaneous/migration_guide#migrating-to-the-batch-request-v3-api and update your configuration to be compatible with the version number 3.\n",
      "    (This message will appear repeatedly until your configuration is updated.)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import great_expectations as ge\n",
    "from great_expectations.dataset import SparkDFDataset\n",
    "from great_expectations.core.batch import BatchRequest\n",
    "import yaml\n",
    "\n",
    "# Initialize a DataContext\n",
    "context = ge.get_context()\n",
    "\n",
    "# Add a PySpark datasource configuration\n",
    "datasource_config = {\n",
    "    \"name\": \"pyspark_df_orders\",\n",
    "    \"class_name\": \"Datasource\",\n",
    "    \"execution_engine\": {\n",
    "        \"module_name\": \"great_expectations.execution_engine\",\n",
    "        \"class_name\": \"SparkDFExecutionEngine\"\n",
    "    },\n",
    "    \"data_connectors\": {\n",
    "        \"default_runtime_data_connector_name\": {\n",
    "            \"class_name\": \"RuntimeDataConnector\",\n",
    "            \"batch_identifiers\": [\"default_identifier_name\"]  # Provide a valid list for batch identifiers\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Add the datasource\n",
    "context.add_datasource(**datasource_config)\n",
    "\n",
    "# Create an expectation suite\n",
    "expectation_suite_name = \"01_ORDERS_TEST_SUITE\"\n",
    "suite = context.add_expectation_suite(expectation_suite_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You appear to be using a legacy capability with the latest config version (3.0).\n",
      "    Your data context with this configuration version uses validation_operators, which are being deprecated.  Please consult the V3 API migration guide https://docs.greatexpectations.io/docs/guides/miscellaneous/migration_guide#migrating-to-the-batch-request-v3-api and update your configuration to be compatible with the version number 3.\n",
      "    (This message will appear repeatedly until your configuration is updated.)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "context = ge.get_context()\n",
    "\n",
    "from great_expectations.core.batch import RuntimeBatchRequest\n",
    "\n",
    "batch_request = RuntimeBatchRequest(\n",
    "    datasource_name=\"my_spark_orders_datasource\",\n",
    "    data_connector_name=\"default_runtime_data_connector_name\",\n",
    "    data_asset_name=\"df\",\n",
    "    runtime_parameters={\"batch_data\": df},\n",
    "    batch_identifiers={\"default_identifier_name\": \"default_identifier_name\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add expectations to the suite\n",
    "suite = context.get_expectation_suite(expectation_suite_name)\n",
    "suite.expectations = [\n",
    "    {\n",
    "        \"expectation_type\": \"expect_column_to_exist\",\n",
    "        \"kwargs\": {\"column\": \"order_id\"}\n",
    "    },\n",
    "    {\n",
    "        \"expectation_type\": \"expect_column_to_exist\",\n",
    "        \"kwargs\": {\"column\": \"customer_id\"}\n",
    "    },\n",
    "    # Add more valid expectations below:\n",
    "    {\n",
    "        \"expectation_type\": \"expect_table_row_count_to_be_between\",\n",
    "        \"kwargs\": {\"min_value\": 10, \"max_value\": 1000}\n",
    "    },\n",
    "    {\n",
    "        \"expectation_type\": \"expect_column_values_to_be_unique\",\n",
    "        \"kwargs\": {\"column\": \"order_id\"}\n",
    "    },\n",
    "    {\n",
    "        \"expectation_type\": \"expect_column_min_to_be_between\",\n",
    "        \"kwargs\": {\"column\": \"order_amount\", \"min_value\": 0, \"max_value\": 1000}\n",
    "    },\n",
    "    {\n",
    "        \"expectation_type\": \"expect_column_mean_to_be_between\",\n",
    "        \"kwargs\": {\"column\": \"order_amount\", \"min_value\": 100, \"max_value\": 500}\n",
    "    },\n",
    "    {\n",
    "        \"expectation_type\": \"expect_column_values_to_match_regex\",\n",
    "        \"kwargs\": {\"column\": \"customer_id\", \"regex\": \"[0-9]*\"}\n",
    "    },\n",
    "]\n",
    "context.save_expectation_suite(suite, expectation_suite_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a Validator for the batch request\n",
    "validator = context.get_validator(\n",
    "    batch_request=batch_request,\n",
    "    expectation_suite_name=expectation_suite_name\n",
    ")\n",
    "\n",
    "# Validate the data\n",
    "validation_results = validator.validate()\n",
    "\n",
    "# Print validation results\n",
    "print(validation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data_context = ge.data_context.DataContext()\n",
    "\n",
    "\"\"\"\n",
    "In Great Expectations, a Validation Operator is a component that manages the validation of data and handles the results of those validations. It orchestrates the validation process, saving results, triggering actions based on the results, and generally managing the validation workflow.\n",
    "\"\"\"\n",
    "\n",
    "validation_results = data_context.run_validation_operator(\n",
    "    \"action_list_operator\",\n",
    "    assets_to_validate=[validator],\n",
    "    run_id=\"my_run_id\"\n",
    ")\n",
    "\n",
    "# Convert validation results to JSON\n",
    "validation_results_json = validation_results.to_json_dict()\n",
    "\n",
    "# Print validation results JSON\n",
    "print(validation_results_json)\n",
    "\n",
    "# Save validation results to a JSON file\n",
    "with open(\"validation_results.json\", \"w\") as json_file:\n",
    "    json.dump(validation_results_json, json_file)\n",
    "\n",
    "# Build Data Docs\n",
    "data_context.build_data_docs()\n",
    "\n",
    "# View Data Docs\n",
    "data_context.open_data_docs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following test cases passed successfully:\n",
      "-  expect_column_to_exist\n",
      "-  expect_column_values_to_be_unique\n",
      "-  expect_column_to_exist\n",
      "-  expect_column_values_to_match_regex\n",
      "-  expect_table_row_count_to_be_between\n",
      "-  expect_column_min_to_be_between\n",
      "-  expect_column_mean_to_be_between\n"
     ]
    }
   ],
   "source": [
    "passed_test_cases = []\n",
    "for result in validation_results[\"results\"]:\n",
    "    if result[\"success\"]:\n",
    "        expectation_type = result[\"expectation_config\"][\"expectation_type\"]\n",
    "        passed_test_cases.append(expectation_type)\n",
    "\n",
    "# Print information about passed test cases\n",
    "if passed_test_cases:\n",
    "    print(\"The following test cases passed successfully:\")\n",
    "    for expectation_type in passed_test_cases:\n",
    "        print(\"- \", expectation_type)\n",
    "else:\n",
    "    print(\"No test cases passed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All test cases passed successfully.\n"
     ]
    }
   ],
   "source": [
    "# If all test cases passed, print a success message\n",
    "if validation_results['success']:\n",
    "    print(\"All test cases passed successfully.\")\n",
    "else:\n",
    "    # If any test case failed, raise an exception\n",
    "    raise Exception(\"Not all test cases passed. Please check the validation results and address the issues.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+\n",
      "|customer_id|total_order_amount|\n",
      "+-----------+------------------+\n",
      "|        858|            375.33|\n",
      "|        243|            407.73|\n",
      "|        883|            907.66|\n",
      "|         65|             254.2|\n",
      "|        879|            464.96|\n",
      "|        588|           1098.02|\n",
      "|        853|            618.22|\n",
      "|        133|            708.42|\n",
      "|        513|            749.76|\n",
      "|        918|            236.09|\n",
      "|        322|            115.82|\n",
      "|        362|             137.3|\n",
      "|        961|             804.9|\n",
      "|        876|             44.33|\n",
      "|        683|           1083.38|\n",
      "|        108|            758.12|\n",
      "|        530|            362.97|\n",
      "|        126|            539.95|\n",
      "|        115|           1218.51|\n",
      "|        210|            407.12|\n",
      "+-----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use case 1: Calculate the total order amount for each customer\n",
    "total_order_amount_per_customer = df.groupBy(\"customer_id\").agg(sum(\"order_amount\").alias(\"total_order_amount\"))\n",
    "total_order_amount_per_customer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+\n",
      "|order_status|order_count|\n",
      "+------------+-----------+\n",
      "|   completed|        313|\n",
      "|        NULL|         57|\n",
      "|   cancelled|        326|\n",
      "|     pending|        304|\n",
      "+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use case 2: Determine the number of orders by status\n",
    "order_count_by_status = df.groupBy(\"order_status\").agg(count(\"order_id\").alias(\"order_count\"))\n",
    "order_count_by_status.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+\n",
      "|order_status|  avg_order_amount|\n",
      "+------------+------------------+\n",
      "|   completed|229.82463333333337|\n",
      "|        NULL|257.70779999999996|\n",
      "|   cancelled|264.07883495145626|\n",
      "|     pending|251.38595238095238|\n",
      "+------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use case 3: Find the average order amount by order status\n",
    "avg_order_amount_by_status = df.groupBy(\"order_status\").agg(avg(\"order_amount\").alias(\"avg_order_amount\"))\n",
    "avg_order_amount_by_status.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+\n",
      "|customer_id|total_order_amount|\n",
      "+-----------+------------------+\n",
      "|        485|           1722.69|\n",
      "|        455|           1693.28|\n",
      "|        365|            1388.1|\n",
      "|          1|           1336.23|\n",
      "|        478|           1324.34|\n",
      "+-----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use case 4: Identify the top 5 customers by total order amount\n",
    "top_customers = total_order_amount_per_customer.orderBy(col(\"total_order_amount\").desc()).limit(5)\n",
    "top_customers.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
